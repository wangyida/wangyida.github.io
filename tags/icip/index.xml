<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>ICIP on Yida Wang</title>
    <link>https://wangyida.github.io/tags/icip/</link>
    <description>Recent content in ICIP on Yida Wang</description>
    <image>
      <title>Yida Wang</title>
      <url>http://campar.in.tum.de/twiki/pub/Main/YidaWang/YidaWang_CAMP.png</url>
      <link>http://campar.in.tum.de/twiki/pub/Main/YidaWang/YidaWang_CAMP.png</link>
    </image>
    <generator>Hugo -- 0.147.6</generator>
    <language>en</language>
    <lastBuildDate>Fri, 01 Apr 2016 10:15:01 +0200</lastBuildDate>
    <atom:link href="https://wangyida.github.io/tags/icip/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Self-restraint Object Recognition by Model Based CNN Learning</title>
      <link>https://wangyida.github.io/posts/icip16/</link>
      <pubDate>Fri, 01 Apr 2016 10:15:01 +0200</pubDate>
      <guid>https://wangyida.github.io/posts/icip16/</guid>
      <description>&lt;h1 id=&#34;abstrarct&#34;&gt;Abstrarct&lt;/h1&gt;
&lt;p&gt;CNN has shown excellent performance on object recognition based on huge amount of real images. For training with synthetic data rendered from 3D models alone to reduce the workload of collecting real images, we propose a concatenated self-restraint learning structure lead by a triplet and softmax jointed loss function for object recognition. Locally connected auto encoder trained from rendered images with and without background used for object reconstruction against environment variables produces an additional channel automatically concatenated to RGB channels as input of classification network. This structure makes it possible training a softmax classifier directly from CNN based on synthetic data with our rendering strategy. Our structure halves the gap between training based on real photos and 3D model in both PASCAL and ImageNet database compared to GoogleNet.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
