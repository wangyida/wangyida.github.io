<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>3DV on Yida Wang</title>
    <link>https://wangyida.github.io/tags/3dv/</link>
    <description>Recent content in 3DV on Yida Wang</description>
    <image>
      <title>Yida Wang</title>
      <url>http://campar.in.tum.de/twiki/pub/Main/YidaWang/YidaWang_CAMP.png</url>
      <link>http://campar.in.tum.de/twiki/pub/Main/YidaWang/YidaWang_CAMP.png</link>
    </image>
    <generator>Hugo -- 0.127.0</generator>
    <language>en</language>
    <lastBuildDate>Sun, 07 Apr 2024 10:15:01 +0200</lastBuildDate>
    <atom:link href="https://wangyida.github.io/tags/3dv/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RaNeuS - Ray-adaptive Neural Surface Reconstruction</title>
      <link>https://wangyida.github.io/posts/3dv24/</link>
      <pubDate>Sun, 07 Apr 2024 10:15:01 +0200</pubDate>
      <guid>https://wangyida.github.io/posts/3dv24/</guid>
      <description>Re-direct to the full PAPER and CODE |
Our objective is to leverage a differentiable radiance field e.g. NeRF to reconstruct detailed 3D surfaces in addition to producing the standard novel view renderings. RaNeuS adaptively adjusts the regularization on the signed distance field so that unsatisfying rendering rays won&amp;rsquo;t enforce strong Eikonal regularization which is ineffective, and allow the gradients from regions with well-learned radiance to effectively back-propagated to the SDF.</description>
    </item>
    <item>
      <title>Rendering, Animating and Meshing Actors with NeRF</title>
      <link>https://wangyida.github.io/posts/synthesia/</link>
      <pubDate>Wed, 30 Nov 2022 10:15:01 +0200</pubDate>
      <guid>https://wangyida.github.io/posts/synthesia/</guid>
      <description> Re-direct to the CODE |
A library for rendering neural actors, and benchmarking dynamic NeRF
Cite If you find this work useful in your research, please cite:
@misc{rama2023wang, Author = {Yida Wang}, Year = {2023}, Note = {https://github.com/wangyida/neural-actor}, Title = {Rendering, Animating and Meshing Actors with NeRF} } </description>
    </item>
    <item>
      <title>Adversarial Semantic Scene Completion from a Single Depth Image</title>
      <link>https://wangyida.github.io/posts/3dv_18/3dv18/</link>
      <pubDate>Tue, 09 Oct 2018 10:15:01 +0200</pubDate>
      <guid>https://wangyida.github.io/posts/3dv_18/3dv18/</guid>
      <description>Re-direct to the full PAPER and CODE |
Abstrarct We propose a method to reconstruct, complete and semantically label a 3D scene from a single input depth image. We improve the accuracy of the regressed semantic 3D maps by a novel architecture based on adversarial learning. In particular, we suggest using multiple adversarial loss terms that not only enforce realistic outputs with respect to the ground truth, but also an effective embedding of the internal features.</description>
    </item>
  </channel>
</rss>
