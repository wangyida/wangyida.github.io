<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>3DV on Yida Wang</title>
    <link>https://wangyida.github.io/tags/3dv/</link>
    <description>Recent content in 3DV on Yida Wang</description>
    <image>
      <url>http://campar.in.tum.de/twiki/pub/Main/YidaWang/YidaWang_CAMP.png</url>
      <link>http://campar.in.tum.de/twiki/pub/Main/YidaWang/YidaWang_CAMP.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 07 Apr 2024 10:15:01 +0200</lastBuildDate><atom:link href="https://wangyida.github.io/tags/3dv/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RaNeuS - Ray-adaptive Neural Surface Reconstruction</title>
      <link>https://wangyida.github.io/posts/3dv24/</link>
      <pubDate>Sun, 07 Apr 2024 10:15:01 +0200</pubDate>
      
      <guid>https://wangyida.github.io/posts/3dv24/</guid>
      <description> Re-direct to the full PAPER and CODE |
Cite If you find this work useful in your research, please cite:
@inproceedings{wang2023raneus, title={RaNeuS: Ray-adaptive Neural Surface Reconstruction}, author={Wang, Yida and Tan, David and Tombari, Federico and Navab, Nassir}, booktitle={Proceedings of the IEEE/CVF International Conference on 3D Vision}, year={2023} } </description>
    </item>
    
    <item>
      <title>Adversarial Semantic Scene Completion from a Single Depth Image</title>
      <link>https://wangyida.github.io/posts/3dv_18/3dv18/</link>
      <pubDate>Tue, 09 Oct 2018 10:15:01 +0200</pubDate>
      
      <guid>https://wangyida.github.io/posts/3dv_18/3dv18/</guid>
      <description>Re-direct to the full PAPER and CODE |
Abstrarct We propose a method to reconstruct, complete and semantically label a 3D scene from a single input depth image. We improve the accuracy of the regressed semantic 3D maps by a novel architecture based on adversarial learning. In particular, we suggest using multiple adversarial loss terms that not only enforce realistic outputs with respect to the ground truth, but also an effective embedding of the internal features.</description>
    </item>
    
  </channel>
</rss>
