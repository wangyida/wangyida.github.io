<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>3D completion | Yida Wang</title><meta name=keywords content>
<meta name=description content="ExampleSite description">
<meta name=author content="Yida">
<link rel=canonical href=https://wangyida.github.io/tags/3d-completion/>
<meta name=google-site-verification content="XYZabc">
<meta name=yandex-verification content="XYZabc">
<meta name=msvalidate.01 content="XYZabc">
<link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<link rel=preload href=/icon_Y.png as=image>
<link rel=icon href=https://wangyida.github.io/icon_Y.png>
<link rel=icon type=image/png sizes=16x16 href=https://wangyida.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=32x32 href=https://wangyida.github.io/icon_Y32x32.png>
<link rel=apple-touch-icon href=https://wangyida.github.io/icon_Y32x32.png>
<link rel=mask-icon href=https://wangyida.github.io/icon_Y32x32.png>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.93.1">
<link rel=alternate type=application/rss+xml href=https://wangyida.github.io/tags/3d-completion/index.xml>
<noscript>
<style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-108746836-1","auto"),ga("send","pageview"))</script><meta property="og:title" content="3D completion">
<meta property="og:description" content="ExampleSite description">
<meta property="og:type" content="website">
<meta property="og:url" content="https://wangyida.github.io/tags/3d-completion/"><meta property="og:image" content="http://campar.in.tum.de/twiki/pub/Main/YidaWang/YidaWang_CAMP.png"><meta property="og:site_name" content="ExampleSite">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="http://campar.in.tum.de/twiki/pub/Main/YidaWang/YidaWang_CAMP.png">
<meta name=twitter:title content="3D completion">
<meta name=twitter:description content="ExampleSite description">
</head><body class=list id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://wangyida.github.io/ accesskey=h title=". WANG (Alt + H)">
<img src=/icon_Y.png alt=logo aria-label=logo height=35>. WANG</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div><ul id=menu>
<li>
<a href=https://wangyida.github.io/archives/ title=archive>
<span>archive</span>
</a>
</li><li>
<a href=https://wangyida.github.io/categories/ title=categories>
<span>categories</span>
</a>
</li><li>
<a href=https://wangyida.github.io/tags/ title=tags>
<span>tags</span>
</a>
</li><li>
<a href=http://campar.in.tum.de/Main/YidaWang title=Lab-site>
<span>Lab-site</span>
</a>
</li></ul></nav></header><main class=main>
<header class=page-header><div class=breadcrumbs><a href=https://wangyida.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://wangyida.github.io/tags/>Tags</a></div><h1>3D completion</h1></header><article class="post-entry tag-entry">
<figure class=entry-cover><img loading=lazy src=https://wangyida.github.io/teasers/thesis_teaser_pami22.png alt="caption for image">
</figure><header class=entry-header>
<h2>Self-supervised Latent Space Optimization with Nebula Variational Coding
</h2></header><section class=entry-content>
<p>| paper | code |
Abstrarct Deep learning approaches process data in a layer-by-layer way with intermediate (or latent) features. We aim at designing a general solution to optimize the latent manifolds to improve the performance on classification, segmentation, completion and/or reconstruction through probabilistic models. This paper proposes a variational inference model which leads to a clustered embedding. We introduce additional variables in the latent space, called nebula anchors, that guide the latent variables to form clusters during training....</p></section><footer class=entry-footer><span title="2022-03-01 10:15:01 +0200 +0200">March 1, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Yida</footer><a class=entry-link aria-label="post link to Self-supervised Latent Space Optimization with Nebula Variational Coding" href=https://wangyida.github.io/posts/2022/youtube/></a>
</article><article class="post-entry tag-entry">
<figure class=entry-cover><img loading=lazy src=https://wangyida.github.io/teasers/thesis_teaser_cvpr22.png alt="caption for image">
</figure><header class=entry-header>
<h2>Learning Local Displacements for Point Cloud Completion
</h2></header><section class=entry-content>
<p>| paper | code |
Abstrarct We propose a novel approach aimed at object and semantic scene completion from a partial scan represented as a 3D point cloud. Our architecture relies on three novel layers that are used successively within an encoder-decoder structure and specifically developed for the task at hand. The first one carries out feature extraction by matching the point features to a set of pre-trained local descriptors. Then, to avoid losing individual descriptors as part of standard operations such as max-pooling, we propose an alternative neighbor-pooling operation that relies on adopting the feature vectors with the highest activations....</p></section><footer class=entry-footer><span title="2022-02-19 10:15:01 +0200 +0200">February 19, 2022</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Yida</footer><a class=entry-link aria-label="post link to Learning Local Displacements for Point Cloud Completion" href=https://wangyida.github.io/posts/2022_1/youtube/></a>
</article><article class="post-entry tag-entry">
<figure class=entry-cover><img loading=lazy src=https://wangyida.github.io/teasers/thesis_teaser_ijcv22.png alt="caption for image">
</figure><header class=entry-header>
<h2>SoftPool++ / An Encoder-Decoder Network for Point Cloud Completion
</h2></header><section class=entry-content>
<p>| paper | code |
Abstrarct We propose a novel convolutional operator for the task of point cloud completion. One striking characteristic of our approach is that, conversely to related work it does not require any max-pooling or voxelization operation. Instead, the proposed operator used to learn the point cloud embedding in the encoder extracts permutation-invariant features from the point cloud via a soft-pooling of feature activations, which are able to preserve fine-grained geometric details....</p></section><footer class=entry-footer><span title="2021-12-29 10:15:01 +0200 +0200">December 29, 2021</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Yida</footer><a class=entry-link aria-label="post link to SoftPool++ / An Encoder-Decoder Network for Point Cloud Completion" href=https://wangyida.github.io/posts/2021/youtube/></a>
</article><article class="post-entry tag-entry">
<figure class=entry-cover><img loading=lazy src=https://wangyida.github.io/teasers/thesis_teaser_eccv20.png alt="caption for image">
</figure><header class=entry-header>
<h2>SoftPoolNet - Shape Descriptor for Point Cloud Completion and Classification
</h2></header><section class=entry-content>
<p>| paper | code |
Abstrarct Point clouds are often the default choice for many applications as they exhibit more flexibility and efficiency than volumetric data. Nevertheless, their unorganized nature – points are stored in an unordered way – makes them less suited to be processed by deep learning pipelines. In this paper, we propose a method for 3D object completion and classification based on point clouds. We introduce a new way of organizing the extracted features based on their activations, which we name soft pooling....</p></section><footer class=entry-footer><span title="2020-08-25 10:15:01 +0200 CEST">August 25, 2020</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Yida</footer><a class=entry-link aria-label="post link to SoftPoolNet - Shape Descriptor for Point Cloud Completion and Classification" href=https://wangyida.github.io/posts/2020/youtube/></a>
</article><article class="post-entry tag-entry">
<figure class=entry-cover><img loading=lazy src=https://wangyida.github.io/teasers/thesis_teaser_iccv19.png alt="caption for image">
</figure><header class=entry-header>
<h2>ForkNet - Multi-Branch Volumetric Semantic Completion From a Single Depth Image
</h2></header><section class=entry-content>
<p>| paper | code |
Abstrarct We propose a novel model for 3D semantic completion from a single depth image, based on a single encoder and three separate generators used to reconstruct different geometric and semantic representations of the original and completed scene, all sharing the same latent space. To transfer information between the geometric and semantic branches of the network, we introduce paths between them concatenating features at corresponding network layers....</p></section><footer class=entry-footer><span title="2019-11-01 10:15:01 +0200 +0200">November 1, 2019</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Yida</footer><a class=entry-link aria-label="post link to ForkNet - Multi-Branch Volumetric Semantic Completion From a Single Depth Image" href=https://wangyida.github.io/posts/2019/youtube/></a>
</article><article class="post-entry tag-entry">
<figure class=entry-cover><img loading=lazy src=https://wangyida.github.io/teasers/thesis_teaser_3dv18.png alt="caption for image">
</figure><header class=entry-header>
<h2>Adversarial Semantic Scene Completion from a Single Depth Image
</h2></header><section class=entry-content>
<p>| paper | code |
Abstrarct We propose a method to reconstruct, complete and semantically label a 3D scene from a single input depth image. We improve the accuracy of the regressed semantic 3D maps by a novel architecture based on adversarial learning. In particular, we suggest using multiple adversarial loss terms that not only enforce realistic outputs with respect to the ground truth, but also an effective embedding of the internal features....</p></section><footer class=entry-footer><span title="2018-10-09 10:15:01 +0200 CEST">October 9, 2018</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Yida</footer><a class=entry-link aria-label="post link to Adversarial Semantic Scene Completion from a Single Depth Image" href=https://wangyida.github.io/posts/2018/youtube/></a>
</article></main><footer class=footer>
<span>&copy; 2022 <a href=https://wangyida.github.io/>Yida Wang</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script>
</body></html>