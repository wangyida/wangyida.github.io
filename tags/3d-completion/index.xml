<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>3D completion on Yida Wang</title>
    <link>https://wangyida.github.io/tags/3d-completion/</link>
    <description>Recent content in 3D completion on Yida Wang</description>
    <image>
      <url>http://campar.in.tum.de/twiki/pub/Main/YidaWang/YidaWang_CAMP.png</url>
      <link>http://campar.in.tum.de/twiki/pub/Main/YidaWang/YidaWang_CAMP.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 01 Mar 2022 10:15:01 +0200</lastBuildDate><atom:link href="https://wangyida.github.io/tags/3d-completion/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Self-supervised Latent Space Optimization with Nebula Variational Coding</title>
      <link>https://wangyida.github.io/posts/pami_22/</link>
      <pubDate>Tue, 01 Mar 2022 10:15:01 +0200</pubDate>
      
      <guid>https://wangyida.github.io/posts/pami_22/</guid>
      <description>Re-direct to the full PAPER and CODE
 Abstrarct Deep learning approaches process data in a layer-by-layer way with intermediate (or latent) features. We aim at designing a general solution to optimize the latent manifolds to improve the performance on classification, segmentation, completion and/or reconstruction through probabilistic models. This paper proposes a variational inference model which leads to a clustered embedding. We introduce additional variables in the latent space, called nebula anchors, that guide the latent variables to form clusters during training.</description>
    </item>
    
    <item>
      <title>Learning Local Displacements for Point Cloud Completion</title>
      <link>https://wangyida.github.io/posts/cvpr_22/</link>
      <pubDate>Sat, 19 Feb 2022 10:15:01 +0200</pubDate>
      
      <guid>https://wangyida.github.io/posts/cvpr_22/</guid>
      <description>Re-direct to the full PAPER and CODE
   Abstrarct    Completing a car       From the input partial scan to our object completion, we visualize the amount of detail in our reconstruction.    We propose a novel approach aimed at object and semantic scene completion from a partial scan represented as a 3D point cloud. Our architecture relies on three novel layers that are used successively within an encoder-decoder structure and specifically developed for the task at hand.</description>
    </item>
    
    <item>
      <title>SoftPool&#43;&#43; / An Encoder-Decoder Network for Point Cloud Completion</title>
      <link>https://wangyida.github.io/posts/youtube/</link>
      <pubDate>Wed, 29 Dec 2021 10:15:01 +0200</pubDate>
      
      <guid>https://wangyida.github.io/posts/youtube/</guid>
      <description>Re-direct to the full PAPER and CODE
 Abstrarct We propose a novel convolutional operator for the task of point cloud completion. One striking characteristic of our approach is that, conversely to related work it does not require any max-pooling or voxelization operation. Instead, the proposed operator used to learn the point cloud embedding in the encoder extracts permutation-invariant features from the point cloud via a soft-pooling of feature activations, which are able to preserve fine-grained geometric details.</description>
    </item>
    
    <item>
      <title>SoftPoolNet, Shape Descriptor for Point Cloud Completion and Classification</title>
      <link>https://wangyida.github.io/posts/eccv_20/</link>
      <pubDate>Tue, 25 Aug 2020 10:15:01 +0200</pubDate>
      
      <guid>https://wangyida.github.io/posts/eccv_20/</guid>
      <description>Re-direct to the full PAPER and CODE
   Abstrarct Point clouds are often the default choice for many applications as they exhibit more flexibility and efficiency than volumetric data. Nevertheless, their unorganized nature &amp;ndash; points are stored in an unordered way &amp;ndash; makes them less suited to be processed by deep learning pipelines. In this paper, we propose a method for 3D object completion and classification based on point clouds.</description>
    </item>
    
    <item>
      <title>Adversarial Semantic Scene Completion from a Single Depth Image</title>
      <link>https://wangyida.github.io/posts/2018/youtube/</link>
      <pubDate>Tue, 09 Oct 2018 10:15:01 +0200</pubDate>
      
      <guid>https://wangyida.github.io/posts/2018/youtube/</guid>
      <description>Re-direct to the full PAPER and CODE |
   Abstrarct We propose a method to reconstruct, complete and semantically label a 3D scene from a single input depth image. We improve the accuracy of the regressed semantic 3D maps by a novel architecture based on adversarial learning. In particular, we suggest using multiple adversarial loss terms that not only enforce realistic outputs with respect to the ground truth, but also an effective embedding of the internal features.</description>
    </item>
    
  </channel>
</rss>
