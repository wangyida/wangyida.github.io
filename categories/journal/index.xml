<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>journal on Yida Wang</title>
    <link>https://wangyida.github.io/categories/journal/</link>
    <description>Recent content in journal on Yida Wang</description>
    <image>
      <url>http://campar.in.tum.de/twiki/pub/Main/YidaWang/YidaWang_CAMP.png</url>
      <link>http://campar.in.tum.de/twiki/pub/Main/YidaWang/YidaWang_CAMP.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 01 Mar 2022 10:15:01 +0200</lastBuildDate><atom:link href="https://wangyida.github.io/categories/journal/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Self-supervised Latent Space Optimization with Nebula Variational Coding</title>
      <link>https://wangyida.github.io/posts/pami_22/</link>
      <pubDate>Tue, 01 Mar 2022 10:15:01 +0200</pubDate>
      
      <guid>https://wangyida.github.io/posts/pami_22/</guid>
      <description>Re-direct to the full PAPER and CODE
 Abstrarct Deep learning approaches process data in a layer-by-layer way with intermediate (or latent) features. We aim at designing a general solution to optimize the latent manifolds to improve the performance on classification, segmentation, completion and/or reconstruction through probabilistic models. This paper proposes a variational inference model which leads to a clustered embedding. We introduce additional variables in the latent space, called nebula anchors, that guide the latent variables to form clusters during training.</description>
    </item>
    
    <item>
      <title>SoftPool&#43;&#43; / An Encoder-Decoder Network for Point Cloud Completion</title>
      <link>https://wangyida.github.io/posts/youtube/</link>
      <pubDate>Wed, 29 Dec 2021 10:15:01 +0200</pubDate>
      
      <guid>https://wangyida.github.io/posts/youtube/</guid>
      <description>Re-direct to the full PAPER and CODE
 Abstrarct We propose a novel convolutional operator for the task of point cloud completion. One striking characteristic of our approach is that, conversely to related work it does not require any max-pooling or voxelization operation. Instead, the proposed operator used to learn the point cloud embedding in the encoder extracts permutation-invariant features from the point cloud via a soft-pooling of feature activations, which are able to preserve fine-grained geometric details.</description>
    </item>
    
    <item>
      <title>Variational Object-aware 3D Hand Pose from a Single RGB Image</title>
      <link>https://wangyida.github.io/posts/2019_1/youtube/</link>
      <pubDate>Sat, 01 Jun 2019 10:15:01 +0200</pubDate>
      
      <guid>https://wangyida.github.io/posts/2019_1/youtube/</guid>
      <description>Re-direct to the full PAPER and CODE |
   Abstrarct We propose an approach to estimate the 3D pose of a human hand while grasping objects from a single RGB image. Our approach is based on a probabilistic model implemented with deep architectures, which is used for regressing, respectively, the 2D hand joints heat maps and the 3D hand joints coordinates. We train our networks so to make our approach robust to large object- and self-occlusions, as commonly occurring with the task at hand.</description>
    </item>
    
    <item>
      <title>Generative Model with Coordinate Metric Learning for Object Recognition Based on 3D Models</title>
      <link>https://wangyida.github.io/posts/2017/youtube/</link>
      <pubDate>Wed, 15 Nov 2017 10:15:01 +0200</pubDate>
      
      <guid>https://wangyida.github.io/posts/2017/youtube/</guid>
      <description>Abstrarct Collecting data for deep learning is so tedious which makes it hard to establish a perfect database. In this paper, we propose a generative model trained with synthetic images rendered from 3D models which can reduce the burden on collecting real training data and make the background conditions more sundry. Our architecture is composed of two subnetworks: semantic foreground object reconstruction network based on Bayesian inference and classification network based on multi-triplet cost training for avoiding over-fitting on monotone synthetic object surface and utilizing accurate informations of synthetic images like object poses and lightning conditions which are helpful for recognizing regular photos.</description>
    </item>
    
  </channel>
</rss>
